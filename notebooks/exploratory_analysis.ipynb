{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melting Point Prediction - Exploratory Data Analysis\n",
    "\n",
    "This notebook demonstrates the exploratory data analysis and model training pipeline for melting point prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import project modules\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.data_loader import MeltingPointDataLoader\n",
    "from src.models import BaseModel, get_default_model_configs\n",
    "from src.train import TrainingPipeline\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"\\nColumns: {list(train_df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyze Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of melting points\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(train_df['melting_point'], bins=30, edgecolor='black')\n",
    "axes[0].set_xlabel('Melting Point (°C)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Melting Points')\n",
    "\n",
    "axes[1].boxplot(train_df['melting_point'])\n",
    "axes[1].set_ylabel('Melting Point (°C)')\n",
    "axes[1].set_title('Box Plot of Melting Points')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Melting Point Statistics:\")\n",
    "print(f\"Mean: {train_df['melting_point'].mean():.2f}°C\")\n",
    "print(f\"Median: {train_df['melting_point'].median():.2f}°C\")\n",
    "print(f\"Std Dev: {train_df['melting_point'].std():.2f}°C\")\n",
    "print(f\"Min: {train_df['melting_point'].min():.2f}°C\")\n",
    "print(f\"Max: {train_df['melting_point'].max():.2f}°C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyze Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature columns\n",
    "feature_cols = [col for col in train_df.columns if col not in ['id', 'melting_point']]\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = train_df[feature_cols].isnull().sum()\n",
    "print(f\"Missing values per feature:\")\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "if missing_values.sum() == 0:\n",
    "    print(\"No missing values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with target\n",
    "correlations = train_df[feature_cols + ['melting_point']].corr()['melting_point'].drop('melting_point')\n",
    "correlations = correlations.sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "correlations.plot(kind='bar')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Correlation with Melting Point')\n",
    "plt.title('Feature Correlations with Melting Point')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTop 5 positively correlated features:\")\n",
    "print(correlations.head())\n",
    "print(f\"\\nTop 5 negatively correlated features:\")\n",
    "print(correlations.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize training pipeline\n",
    "pipeline = TrainingPipeline(\n",
    "    train_path='../data/train.csv',\n",
    "    test_path='../data/test.csv',\n",
    "    model_dir='../models'\n",
    ")\n",
    "\n",
    "# Load and prepare data\n",
    "X_train, X_val, y_train, y_val = pipeline.load_and_prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all models\n",
    "results = pipeline.train_all_models(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract validation metrics\n",
    "model_names = []\n",
    "val_maes = []\n",
    "val_rmses = []\n",
    "val_r2s = []\n",
    "\n",
    "for model_name, result in results.items():\n",
    "    model_names.append(model_name)\n",
    "    val_maes.append(result['val_metrics']['mae'])\n",
    "    val_rmses.append(result['val_metrics']['rmse'])\n",
    "    val_r2s.append(result['val_metrics']['r2'])\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': model_names,\n",
    "    'Val MAE': val_maes,\n",
    "    'Val RMSE': val_rmses,\n",
    "    'Val R²': val_r2s\n",
    "})\n",
    "\n",
    "comparison_df = comparison_df.sort_values('Val MAE')\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "axes[0].barh(comparison_df['Model'], comparison_df['Val MAE'])\n",
    "axes[0].set_xlabel('MAE')\n",
    "axes[0].set_title('Validation MAE by Model')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "axes[1].barh(comparison_df['Model'], comparison_df['Val RMSE'])\n",
    "axes[1].set_xlabel('RMSE')\n",
    "axes[1].set_title('Validation RMSE by Model')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "axes[2].barh(comparison_df['Model'], comparison_df['Val R²'])\n",
    "axes[2].set_xlabel('R²')\n",
    "axes[2].set_title('Validation R² by Model')\n",
    "axes[2].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Ensemble and Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ensemble model\n",
    "ensemble = pipeline.create_ensemble(\n",
    "    model_types=list(results.keys()),\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on test set\n",
    "submission = pipeline.generate_predictions(\n",
    "    model_name='ensemble',\n",
    "    output_path='../submission.csv'\n",
    ")\n",
    "\n",
    "print(f\"\\nSubmission file created!\")\n",
    "print(f\"\\nFirst few predictions:\")\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyze Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prediction distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(submission['melting_point'], bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Predicted Melting Point (°C)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Predicted Melting Points')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(train_df['melting_point'], bins=30, edgecolor='black', alpha=0.7, label='Training')\n",
    "plt.hist(submission['melting_point'], bins=30, edgecolor='black', alpha=0.7, label='Predictions')\n",
    "plt.xlabel('Melting Point (°C)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Training vs Predicted Distribution')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Loading and exploring the melting point dataset\n",
    "2. Analyzing the target variable and feature correlations\n",
    "3. Training multiple machine learning models\n",
    "4. Comparing model performance using MAE, RMSE, and R² metrics\n",
    "5. Creating an ensemble model\n",
    "6. Generating predictions for submission\n",
    "\n",
    "The best model can be selected based on validation MAE, and the ensemble often provides improved performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
